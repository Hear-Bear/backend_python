# dataset.py
# FSD50KSubsetDataset í´ë˜ìŠ¤ì™€ prepare_data í•¨ìˆ˜ ì •ì˜

import os

import librosa
import numpy as np
import pandas as pd
import torch
import torchaudio.transforms as T
from audiomentations import (
    Compose,
    TimeStretch,
    PitchShift,
    Gain,
    ApplyImpulseResponse,
    LowPassFilter,
    AddBackgroundNoise,
    SomeOf
)
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset

import config


# 3. [ì¶”ê°€] ğŸŒŸ ì œê³µí•´ì£¼ì‹  ê³ ê¸‰ ì¦ê°• íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜
def get_advanced_indoor_pipeline(
        sample_rate,
        background_sounds_path=None,
        ir_sounds_path=None
):
    """
    ì‹¤ë‚´ í™˜ê²½(ìš¸ë¦¼, ì°¨í)ì— íŠ¹í™”ëœ ê³ ê¸‰ ì¦ê°• íŒŒì´í”„ë¼ì¸
    """

    # Level 1: ì†Œë¦¬ ìì²´ë¥¼ ë³€í˜•í•˜ëŠ” ê¸°ë³¸ ì¦ê°• ë¦¬ìŠ¤íŠ¸
    core_transforms = [
        Gain(min_gain_db=-3.0, max_gain_db=3.0, p=0.5),
        PitchShift(min_semitones=-1.5, max_semitones=1.5, p=0.5),
        TimeStretch(min_rate=0.9, max_rate=1.1, p=0.5),
    ]

    # Level 2: ê³µê°„/í™˜ê²½ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ê³ ê¸‰ ì¦ê°• ë¦¬ìŠ¤íŠ¸
    environmental_transforms = []

    if background_sounds_path:
        environmental_transforms.append(
            AddBackgroundNoise(
                sounds_path=background_sounds_path,
                min_snr_db=3.0,
                max_snr_db=15.0,
                p=0.6
            )
        )

    if ir_sounds_path:
        environmental_transforms.append(
            ApplyImpulseResponse(
                ir_path=ir_sounds_path,
                p=0.5
            )
        )

    environmental_transforms.append(
        LowPassFilter(
            min_cutoff_freq=2000,
            max_cutoff_freq=4000,
            p=0.4,
        )
    )

    return Compose(
        transforms=[
            SomeOf(
                transforms=environmental_transforms,
                num_transforms=(0, 2),
                p=1.0
            ),
            SomeOf(
                transforms=core_transforms,
                num_transforms=(1, 3),
                p=1.0
            )
        ],
        p = 1.0
    )


class FSD50KSubsetDataset(Dataset):
    # FSD50K ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ, ì¦ê°•, í”¼ì²˜ ì¶”ì¶œì„ ë‹´ë‹¹í•˜ëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹

    def __init__(self, df, audio_dir, feature_extractor, use_augmentation=None):
        self.df = df
        self.audio_dir = audio_dir
        self.feature_extractor = feature_extractor
        self.target_sr = feature_extractor.sampling_rate

        if use_augmentation:
            # config.pyì—ì„œ ê²½ë¡œë¥¼ ê°€ì ¸ì˜¤ë˜, ì‹¤ì œ ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸
            bg_path = config.BACKGROUND_NOISE_DIR
            ir_path = config.IMPULSE_RESPONSE_DIR

            valid_bg_path = bg_path if bg_path and os.path.isdir(bg_path) else None
            valid_ir_path = ir_path if ir_path and os.path.isdir(ir_path) else None

            # ê²½ë¡œê°€ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ê²½ê³  ì¶œë ¥ (í•™ìŠµì€ ì§„í–‰ë¨)
            if bg_path and not valid_bg_path:
                print(f"ê²½ê³ : config.pyì˜ BACKGROUND_NOISE_DIR '{bg_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°°ê²½ ì†ŒìŒ ì¦ê°•ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            if ir_path and not valid_ir_path:
                print(f"ê²½ê³ : config.pyì˜ IMPULSE_RESPONSE_DIR '{ir_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìš¸ë¦¼(IR) ì¦ê°•ì„ ê±´ë„ˆëœë‹ˆë‹¤.")

            # íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ self.augmentì— í• ë‹¹
            self.augment = get_advanced_indoor_pipeline(
                sample_rate=self.target_sr,
                background_sounds_path=valid_bg_path,
                ir_sounds_path=valid_ir_path
            )

            # SpecAugment íŒŒì´í”„ë¼ì¸ ì •ì˜
            self.use_spec_augment = True
            self.spec_augmenter = torch.nn.Sequential(
                # (batch, freq, time) -> (batch, 128, 1024)
                # 128ê°œì˜ ì£¼íŒŒìˆ˜ ë¹ˆ ì¤‘ ìµœëŒ€ 20ê°œë¥¼ ê°€ë¦¼
                T.FrequencyMasking(freq_mask_param=20),
                # 1024ê°œì˜ ì‹œê°„ í”„ë ˆì„ ì¤‘ ìµœëŒ€ 50ê°œë¥¼ ê°€ë¦¼
                T.TimeMasking(time_mask_param=50)
            )
        else:
            self.augment = None
            self.use_spec_augment = False

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        file_path = os.path.join(self.audio_dir, f"{row['fname']}.wav")

        try:
            wav, sr = librosa.load(file_path, sr=self.target_sr, mono=True)
        except Exception as e:
            print(f"ì˜¤ë¥˜: íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}. ì›ì¸: {e}")
            print("ê²½ê³ : 5ì´ˆ ë¶„ëŸ‰ì˜ ë¹ˆ ì˜¤ë””ì˜¤ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            wav = np.zeros(self.target_sr * 5)

        if self.augment:
            wav = self.augment(samples=wav, sample_rate=self.target_sr)

        inputs = self.feature_extractor(
            wav,
            sampling_rate=self.target_sr,
            return_tensors="pt",
            padding="max_length",
            truncation=True,
            max_length=config.MAX_AUDIO_LENGTH
        )
        input_values = inputs.input_values.squeeze(0)

        # SpecAugment ì ìš©
        if self.use_spec_augment:
            # (Time, Freq) -> (Freq, Time)ë¡œ ì¶• ë³€ê²½
            input_values = input_values.transpose(0, 1)
            # (Freq, Time) -> (Batch, Freq, Time)ë¡œ ì„ì‹œ ë³€ê²½ (1, 128, 1024)
            input_values = input_values.unsqueeze(0)

            input_values = self.spec_augmenter(input_values)  # ë§ˆìŠ¤í‚¹ ì ìš©

            # (Batch, Freq, Time) -> (Freq, Time)
            input_values = input_values.squeeze(0)
            # (Freq, Time) -> (Time, Freq)ë¡œ ì›ë³µ
            input_values = input_values.transpose(0, 1)

        return {
            "input_values": input_values,
            "labels": torch.tensor(row['labels_vector'], dtype=torch.float)
        }


def prepare_data(dev_csv, eval_csv, class_groups, dev_audio_dir, eval_audio_dir, val_split_size, random_seed):
    # class_groups ë”•ì…”ë„ˆë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ train/eval ë°ì´í„°í”„ë ˆì„ê³¼ ë ˆì´ë¸” ë§µì„ ë°˜í™˜.
    print("\n-------------------------- ë°ì´í„° ì¤€ë¹„ ì‹œì‘ --------------------------")

    # ìƒˆë¡œìš´ ë ˆì´ë¸” ë§µ ìƒì„± (e.g., {'Dog': 0, 'Cat': 1, 'Alarm': 2, ...})
    new_labels = list(class_groups.keys())
    num_classes = len(new_labels)
    label2id = {name: i for i, name in enumerate(new_labels)}
    id2label = {i: name for i, name in enumerate(new_labels)}

    # ì—­ë°©í–¥ ì¡°íšŒ ë§µ ìƒì„± (ë¹ ë¥¸ í•„í„°ë§ ìš©) (e.g., {'Dog': 0, 'Bark': 0, 'Cat': 1, 'Meow': 1, ...})
    source_label_to_group_id = {}
    for group_name, source_labels in class_groups.items():
        group_id = label2id[group_name]
        for source_label in source_labels:
            if source_label in source_label_to_group_id:
                print(f"ê²½ê³ : '{source_label}'ì´ ì—¬ëŸ¬ ê·¸ë£¹ì— í¬í•¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ê·¸ë£¹ '{group_name}'ì— í• ë‹¹ë©ë‹ˆë‹¤.")
            source_label_to_group_id[source_label] = group_id

    print(f"ì´ {len(source_label_to_group_id)}ê°œì˜ ì›ë³¸ ë ˆì´ë¸”ì„ {len(label2id)}ê°œì˜ ê·¸ë£¹ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.")

    def filter_dataframe(csv_path, audio_dir):
        # CSVë¥¼ ë¡œë“œí•˜ê³  'source_label_to_group_id' ë§µì„ ì‚¬ìš©í•´ í•„í„°ë§
        try:
            df = pd.read_csv(csv_path)
        except FileNotFoundError:
            print(f"ì˜¤ë¥˜: {csv_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        filtered_data = []
        for _, row in df.iterrows():
            file_labels = row['labels'].split(',')  # e.g., ["Dog", "Speech"]
            found_group_ids = set()

            # íŒŒì¼ì˜ ë ˆì´ë¸” ì¤‘, Target Classì— ìˆëŠ”ì§€ í™•ì¸
            for label in file_labels:
                if label in source_label_to_group_id:
                    found_group_ids.add(source_label_to_group_id[label])

            if found_group_ids:
                if os.path.exists(f"{audio_dir}/{row['fname']}.wav"):

                    # Multi-Hot Vector ìƒì„±
                    labels_vector = np.zeros(num_classes, dtype=int)
                    for group_id in found_group_ids:
                        labels_vector[group_id] = 1

                    filtered_data.append({
                        "fname": row['fname'],
                        "labels_vector": labels_vector.tolist() # ë²¡í„° ì €ì¥
                    })

        if not filtered_data:
            print(f"ê²½ê³ : {csv_path}ì—ì„œ íƒ€ê²Ÿ í´ë˜ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        return pd.DataFrame(filtered_data)

    # í•™ìŠµ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    print(f"\n--- í•™ìŠµ ë°ì´í„° ì²˜ë¦¬: {dev_csv} ---")
    train_df = filter_dataframe(dev_csv, dev_audio_dir)
    if train_df is None or train_df.empty:
        print("ì˜¤ë¥˜: í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None, None, None  # 5ê°œ ë°˜í™˜

    train_df, val_df = train_test_split(
        train_df,
        test_size=val_split_size,
        random_state=random_seed,
        # stratify=train_df['label2id']  # ë ˆì´ë¸” ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ë¶„ë¦¬
    )

    # Train Set ê¸°ì¤€ìœ¼ë¡œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    print("--- í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (Train Set ê¸°ì¤€) ---")

    # ê° í´ë˜ìŠ¤ë³„ Positive(1) ê°œìˆ˜ ê³„ì‚°
    train_labels_matrix = np.array(train_df['labels_vector'].tolist())
    positive_counts = np.sum(train_labels_matrix, axis=0)  # ì˜ˆ: [10, 1000, 5, ...]

    # ì „ì²´ ë°ì´í„° ê°œìˆ˜ (N)
    total_samples = len(train_df)

    # Negative(0) ê°œìˆ˜ ê³„ì‚°
    negative_counts = total_samples - positive_counts

    # pos_weight ê³µì‹ ë³€ê²½
    # ê³µì‹: (Negative ê°œìˆ˜) / (Positive ê°œìˆ˜)
    # ì˜ë¯¸: "Positiveê°€ í¬ê·€í• ìˆ˜ë¡(ë¶„ëª¨ê°€ ì‘ì„ìˆ˜ë¡) ê°€ì¤‘ì¹˜ë¥¼ ë†’ê²Œ ì¤˜ë¼"
    # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€ ìœ„í•´ 1e-6 ëŒ€ì‹ , clipì´ë‚˜ max ì‚¬ìš©
    pos_weights = np.sqrt(negative_counts / (positive_counts + 1e-6))

    # ë„ˆë¬´ í° ê°€ì¤‘ì¹˜(í­ë°œ ìœ„í—˜) ë°©ì§€: ìµœëŒ€ 100ë°°ê¹Œì§€ë§Œ í—ˆìš© (ì„ íƒì‚¬í•­ì´ì§€ë§Œ ì•ˆì „í•¨)
    pos_weights = np.clip(pos_weights, 1.0, 50.0)
    # pos_weights = np.maximum(pos_weights, 1.0)

    print(f"í´ë˜ìŠ¤ë³„ Positive ìˆ˜ (ì¼ë¶€): {positive_counts.astype(int)}")
    print(f"ìˆ˜ì •ëœ pos_weight (ì¼ë¶€): {pos_weights[:5].round(2)}")
    # ì˜ˆìƒ ê²°ê³¼: [88.4, 8.8, 100.0, ...] ì²˜ëŸ¼ 1ë³´ë‹¤ í° ê°’ë“¤ì´ ë‚˜ì™€ì•¼ í•¨

    # PyTorch í…ì„œë¡œ ë³€í™˜
    class_weights_tensor = torch.tensor(pos_weights, dtype=torch.float)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    print(f"\n--- í‰ê°€(test) ë°ì´í„° ì²˜ë¦¬: {eval_csv} ---")
    test_df = filter_dataframe(eval_csv, eval_audio_dir)
    if test_df is None:
        print("ê²½ê³ : í‰ê°€(eval) ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìµœì¢… í…ŒìŠ¤íŠ¸ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        test_df = pd.DataFrame()  # ë¹ˆ DFë¼ë„ ë°˜í™˜

    print(f"í•„í„°ë§ëœ ì´ ë°ì´í„°: (Train: {len(train_df)} / Eval: {len(test_df)})")
    print("-------------------------- ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ --------------------------")

    return train_df, val_df, test_df, label2id, id2label, class_weights_tensor